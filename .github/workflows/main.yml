name: Scrape and Deploy Dashboard

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch: # Allow manual trigger

jobs:
  scrape-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install Chrome
      uses: browser-actions/setup-chrome@latest
    
    - name: Install ChromeDriver
      uses: nanasess/setup-chromedriver@v2
    
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create downloads directory
      run: mkdir -p downloads
    
    - name: Run scraper
      env:
        AWS_ACCESS_KEY: ${{ secrets.AWS_ACCESS_KEY }}
        AWS_SECRET_KEY: ${{ secrets.AWS_SECRET_KEY }}
        MATHNASIUM_USERNAME: ${{ secrets.MATHNASIUM_USERNAME }}
        MATHNASIUM_PASSWORD: ${{ secrets.MATHNASIUM_PASSWORD }}
      run: python scrape.py
    
    - name: Run dashboard and process data
      env:
        AWS_ACCESS_KEY: ${{ secrets.AWS_ACCESS_KEY }}
        AWS_SECRET_KEY: ${{ secrets.AWS_SECRET_KEY }}
      run: |
        # Run the dashboard which includes data processing
        # Set environment variable to prevent server from starting
        export DASH_NO_SERVER=1
        python mathDash_s3.py
        
    - name: Trigger Render Deploy
      env:
        RENDER_DEPLOY_HOOK_URL: ${{ secrets.RENDER_DEPLOY_HOOK_URL }}
      run: |
        python -c "
        import os, requests
        url = os.environ['RENDER_DEPLOY_HOOK_URL']
        response = requests.post(url)
        print(response.status_code, response.text)
        response.raise_for_status()
        "
