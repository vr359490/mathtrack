name: Scrape and Deploy Dashboard

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch: # Allow manual trigger

jobs:
  scrape-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install Chrome
      uses: browser-actions/setup-chrome@latest
    
    - name: Install ChromeDriver
      uses: nanasess/setup-chromedriver@v2
    
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create downloads directory
      run: mkdir -p downloads
    
    - name: Run scraper
      env:
        AWS_ACCESS_KEY: ${{ secrets.AWS_ACCESS_KEY }}
        AWS_SECRET_KEY: ${{ secrets.AWS_SECRET_KEY }}
        MATHNASIUM_USERNAME: ${{ secrets.MATHNASIUM_USERNAME }}
        MATHNASIUM_PASSWORD: ${{ secrets.MATHNASIUM_PASSWORD }}
      run: |
        # The scraper needs modification to work in CI environment
        # For now, we'll create a modified version
        python scrape.py

    
    - name: Test dashboard compilation
      env:
        AWS_ACCESS_KEY: ${{ secrets.AWS_ACCESS_KEY }}
        AWS_SECRET_KEY: ${{ secrets.AWS_SECRET_KEY }}
      run: |
        # Test that the dashboard can be imported without errors
        python -c "import mathDash_s3; print('Dashboard compiled successfully')"
